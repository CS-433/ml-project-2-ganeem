{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# handles the loading and preprocessing of the data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets accelerate torch pandas tqdm scikit-learn\n",
    "!pip install optuna\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import optuna\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import optuna\n",
    "\n",
    "# for warning\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "def load_text_file(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        return [line.strip() for line in f]\n",
    "\n",
    "use_full_dataset = True\n",
    "\n",
    "if use_full_dataset:\n",
    "    pos_file = \"/data/train_pos_full.txt\"\n",
    "    neg_file = \"/data/train_neg_full.txt\"\n",
    "else:\n",
    "    pos_file = \"/data/train_pos.txt\"\n",
    "    neg_file = \"/data/train_neg.txt\"\n",
    "\n",
    "positive_texts = load_text_file(pos_file)\n",
    "negative_texts = load_text_file(neg_file)\n",
    "\n",
    "train_texts = positive_texts + negative_texts\n",
    "train_labels = [1] * len(positive_texts) + [0] * len(negative_texts)\n",
    "\n",
    "# validation split\n",
    "val_size = int(0.1 * len(train_texts))\n",
    "dataset = DatasetDict({\n",
    "    'train': Dataset.from_dict({\n",
    "        'text': train_texts[val_size:],\n",
    "        'label': train_labels[val_size:]\n",
    "    }),\n",
    "    'validation': Dataset.from_dict({\n",
    "        'text': train_texts[:val_size],\n",
    "        'label': train_labels[:val_size]\n",
    "    })\n",
    "})\n",
    "\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Basic preprocessing (not needed but is from the hugging face example)\n",
    "    texts = [text.replace('@user', '@USERNAME') for text in examples['text']]\n",
    "    texts = [text.replace('http', 'URL') for text in texts]\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=None\n",
    "    )\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Load model\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(\n",
    " #   MODEL,\n",
    " #   num_labels=2, # pos and negative\n",
    "#    ignore_mismatched_sizes=True\n",
    "#)\n",
    "\n",
    "# Define metrics for evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = (predictions == labels).mean()\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL,\n",
    "        num_labels=2,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This cell handles the hyperparameter search and creates a model with the best hyperparameterrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "initial_training_args = TrainingArguments(\n",
    "    output_dir=\"./binary-sentiment-finetuned-search\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# nitialize first trainer for hyperparameter search\n",
    "search_trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=initial_training_args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# run hyperparameter search\n",
    "best_run = search_trainer.hyperparameter_search(\n",
    "    backend=\"optuna\",\n",
    "    n_trials=10,\n",
    "    direction=\"maximize\",\n",
    "    hp_space=lambda trial: {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 1, 5),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [1028]),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.01, 0.1, log=True),\n",
    "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0.0, 0.2),\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters:\", best_run.hyperparameters)\n",
    "\n",
    "# choose new training arguments with best hyperparameters\n",
    "final_training_args = TrainingArguments(\n",
    "    output_dir=\"./binary-sentiment-finetuned-final\",\n",
    "    learning_rate=best_run.hyperparameters[\"learning_rate\"],\n",
    "    per_device_train_batch_size=best_run.hyperparameters[\"per_device_train_batch_size\"],\n",
    "    num_train_epochs=best_run.hyperparameters[\"num_train_epochs\"],\n",
    "    weight_decay=best_run.hyperparameters[\"weight_decay\"],\n",
    "    warmup_ratio=best_run.hyperparameters[\"warmup_ratio\"],\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Initialize final trainer with best hyperparameters\n",
    "final_trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=final_training_args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train final model\n",
    "final_trainer.train()\n",
    "\n",
    "# Keep a reference to the final model for inference\n",
    "model = final_trainer.model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contains an example for finetuning the model with specified trianing arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "output_dir=\"./binary-sentiment-finetuned-full\",\n",
    "    learning_rate= 4.030628115465328e-05,\n",
    "    num_train_epochs= 3,\n",
    "    per_device_train_batch_size= 1028,\n",
    "    weight_decay= 0.016583152835062398,\n",
    "    warmup_ratio= 0.08091678678536013,                    \n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",             \n",
    "    push_to_hub=False,\n",
    "    fp16=True                           \n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does inference on the trained model and outputs the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def predict_sentiment_batch(texts, model, tokenizer, device, max_length=40, batch_size=64):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    # process in batches\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            predictions.extend(outputs.logits.argmax(dim=-1).cpu().numpy())\n",
    "\n",
    "    # convert 0/1 to -1/1 (could change in the Trainer)\n",
    "    return [1 if pred == 1 else -1 for pred in predictions]\n",
    "\n",
    "# get device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# get model from trainer and move to device\n",
    "model = trainer.model\n",
    "model = model.to(device)\n",
    "\n",
    "# load test data\n",
    "test_texts = load_text_file(\"/data/test_data.txt\")\n",
    "\n",
    "# make the predictions\n",
    "predictions = predict_sentiment_batch(\n",
    "    test_texts,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    max_length=MAX_LENGTH,\n",
    "    batch_size=training_args.per_device_train_batch_size\n",
    ")\n",
    "\n",
    "# create DataFrame with Id and Prediction\n",
    "df = pd.DataFrame({\n",
    "    'Id': range(1, len(predictions) + 1),\n",
    "    'Prediction': predictions\n",
    "})\n",
    "\n",
    "# save the result to CSV file\n",
    "df.to_csv('predictions.csv', index=False)\n",
    "print(\"Predictions saved to predictions.csv\")\n",
    "\n",
    "# quick display first few predictions\n",
    "print(\"\\nFirst few predictions:\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a util function that finds good max_length for tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "def analyze_text_lengths(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        texts = [line.strip() for line in f]\n",
    "\n",
    "    lengths = [len(tokenizer.encode(text)) for text in texts]\n",
    "\n",
    "    stats = {\n",
    "        'mean': np.mean(lengths),\n",
    "        'median': np.median(lengths),\n",
    "        'max': np.max(lengths),\n",
    "        'min': np.min(lengths),\n",
    "        '95th_percentile': np.percentile(lengths, 95),\n",
    "        'total_samples': len(lengths)\n",
    "    }\n",
    "\n",
    "    return lengths, stats\n",
    "\n",
    "files = [\n",
    "    '/data/train_pos.txt',\n",
    "    '/data/train_neg.txt',\n",
    "    '/data/test_data.txt'\n",
    "]\n",
    "\n",
    "all_stats = {}\n",
    "all_lengths = {}\n",
    "\n",
    "for file_path in files:\n",
    "    print(f\"\\nAnalyzing {file_path.split('/')[-1]}:\")\n",
    "    lengths, stats = analyze_text_lengths(file_path)\n",
    "    all_stats[file_path] = stats\n",
    "    all_lengths[file_path] = lengths\n",
    "\n",
    "    print(f\"Number of samples: {stats['total_samples']}\")\n",
    "    print(f\"Mean length: {stats['mean']:.2f}\")\n",
    "    print(f\"Median length: {stats['median']:.2f}\")\n",
    "    print(f\"Max length: {stats['max']}\")\n",
    "    print(f\"95th percentile: {stats['95th_percentile']:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "all_95th = max(stats['95th_percentile'] for stats in all_stats.values())\n",
    "all_max = max(stats['max'] for stats in all_stats.values())\n",
    "\n",
    "print(f\"all texts): {int(all_max)}\")\n",
    "print(f\"95% of texts): {int(all_95th)}\")\n",
    "print(f\"Efficient: {int(max(stats['median'] for stats in all_stats.values()) * 1.5)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
